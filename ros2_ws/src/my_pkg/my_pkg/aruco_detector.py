import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge
import cv2
import numpy as np
import tf2_ros
from geometry_msgs.msg import PoseStamped
from moma_interfaces.msg import MarkerArray, MarkerInfo
import tf2_geometry_msgs
from scipy.spatial.transform import Rotation
from std_msgs.msg import Bool

class ArucoDetector(Node):
    def __init__(self):
        super().__init__('aruco_detector_left')
        
        # [ìˆ˜ì •] ë§ˆì»¤ ë° ê²€ì¶œê¸° ì„¤ì • (OpenCV 4.7+ ëŒ€ì‘)
        self.marker_size = 0.13
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
        
        # 1. íŒŒë¼ë¯¸í„° ìƒì„±ìž ë³€ê²½ (_create í•¨ìˆ˜ ì‚­ì œë¨)
        self.params = cv2.aruco.DetectorParameters()
        
        # 2. ArucoDetector ê°ì²´ ìƒì„± (ê²€ì¶œ ì†ë„ ë° ìµœì í™” ìœ ë¦¬)
        self.detector = cv2.aruco.ArucoDetector(self.aruco_dict, self.params)
        
        self.bridge = CvBridge()
        
        # TF ë¦¬ìŠ¤ë„ˆ
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)

        # ì¹´ë©”ë¼ êµ¬ë…
        self.create_subscription(Image, '/left_camera/rgb', self.image_callback, 10)
        self.create_subscription(CameraInfo, '/left_camera/camera_info', self.info_callback, 10)
        
        # RMPFlow íƒ€ê²Ÿ í¼ë¸”ë¦¬ì…”(ë””ë²„ê¹…ìš©)
        # self.pose_pub = self.create_publisher(PoseStamped, '/rmp_target_pose', 10)
        
        # [On/Off ìŠ¤ìœ„ì¹˜] ì™¸ë¶€ì—ì„œ Trueë¥¼ ë³´ë‚´ë©´ ê²€ì¶œ ì‹œìž‘
        self.create_subscription(Bool, '/vision/enable_left', self.enable_callback, 10)
        
        # [ê²°ê³¼ ì†¡ì‹ ] ì§ì ‘ ì œì–´(/rmp_target_pose) ëŒ€ì‹  ì •ë³´ë§Œ ì œê³µ
        self.result_pub = self.create_publisher(MarkerArray, '/vision/left_markers', 10)
        
        # ìƒíƒœ ë³€ìˆ˜
        self.is_enabled = False  # ê¸°ë³¸ê°’: êº¼ì§
        
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # ê·¸ë¦¬í¼ê°€ ë°”ë‹¥ì„ í–¥í•˜ëŠ” orientation (ì›ëž˜ ì½”ë“œì™€ ë™ì¼)
        euler = np.array([0, np.pi/2, 0])  # roll, pitch, yaw
        rot = Rotation.from_euler('xyz', euler)
        self.default_quat = rot.as_quat()  # [x, y, z, w]
        
        self.get_logger().info("âœ… Front Camera Detector Ready (Waiting for Enable Signal...)")
        
    
    def enable_callback(self, msg):
        """On/Off ìŠ¤ìœ„ì¹˜ ì½œë°±"""
        if msg.data and not self.is_enabled:
            self.get_logger().info("ðŸŸ¢ Detector STARTED")
            self.is_enabled = True
        elif not msg.data and self.is_enabled:
            self.get_logger().info("ðŸ”´ Detector STOPPED")
            self.is_enabled = False

    def info_callback(self, msg):
        if self.camera_matrix is None:
            self.camera_matrix = np.array(msg.k).reshape((3, 3))
            self.dist_coeffs = np.array(msg.d)

    def image_callback(self, msg):
        # 1. êº¼ì ¸ìžˆê±°ë‚˜ ì¹´ë©”ë¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
        if not self.is_enabled or self.camera_matrix is None:
            return

        try:
            frame = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except: return

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        corners, ids, rejected = self.detector.detectMarkers(gray)

        if ids is not None:
            # ë³´ë‚¼ ë©”ì‹œì§€ ê°ì²´ ìƒì„±
            marker_array = MarkerArray()
            marker_array.header.stamp = self.get_clock().now().to_msg()
            marker_array.header.frame_id = "base_link" # ìµœì¢… ì¢Œí‘œê³„ ê¸°ì¤€
            
            # 3D ì¢Œí‘œ ê³„ì‚°ì„ ìœ„í•œ ë§ˆì»¤ ì •ì˜
            marker_half = self.marker_size / 2.0
            obj_points = np.array([
                [-marker_half, marker_half, 0],
                [marker_half, marker_half, 0],
                [marker_half, -marker_half, 0],
                [-marker_half, -marker_half, 0]
            ], dtype=np.float32)

            # ëª¨ë“  ê²€ì¶œëœ ë§ˆì»¤ì— ëŒ€í•´ ìˆ˜í–‰
            for i in range(len(ids)):
                current_id = int(ids[i][0])
                # solvePnPë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë§ˆì»¤ì˜ í¬ì¦ˆ ê³„ì‚°
                _, rvec, tvec = cv2.solvePnP(
                    obj_points, 
                    corners[i][0], 
                    self.camera_matrix, 
                    self.dist_coeffs
                )

                # ì‹œê°í™” ì²˜ë¦¬ (ì°¨ì› ë¬¸ì œë¡œ ì¸í•´ rvec, tvec í˜•íƒœ ì£¼ì˜)
                cv2.aruco.drawDetectedMarkers(frame, corners, ids)
                cv2.drawFrameAxes(frame, self.camera_matrix, self.dist_coeffs, rvec, tvec, 0.1)

                try:
                    # ---------------------------------------------------------
                    # [ìˆ˜ì •] ë¡œì»¬ ì˜¤í”„ì…‹ ì ìš©ì„ ìœ„í•œ í–‰ë ¬ ì—°ì‚°
                    # ---------------------------------------------------------
                    
                    # (1) rvec(íšŒì „ë²¡í„°) -> R(3x3 íšŒì „í–‰ë ¬) ë³€í™˜
                    R, _ = cv2.Rodrigues(rvec)
                    
                    # (2) ë§ˆì»¤ì˜ ë³€í™˜ í–‰ë ¬ (4x4) ìƒì„± (ì¹´ë©”ë¼ ê¸°ì¤€ ë§ˆì»¤ ìœ„ì¹˜)
                    T_cam_marker = np.eye(4)
                    T_cam_marker[:3, :3] = R
                    T_cam_marker[:3, 3] = tvec.squeeze()
                    
                    # (3) ì˜¤í”„ì…‹ í–‰ë ¬ ìƒì„± (ë§ˆì»¤ ê¸°ì¤€ ë¡œì»¬ ì˜¤í”„ì…‹)
                    # OpenCV Aruco ì¢Œí‘œê³„ ê¸°ì¤€: X(ìš°), Y(í•˜), Z(ì „ë°©)
                    # ëª©í‘œ: ë§ˆì»¤ ë’¤ìª½(íŠœë¸Œ ì¤‘ì‹¬) + ë§ˆì»¤ ìœ„ìª½(íŠœë¸Œ ìƒë‹¨)
                    T_offset = np.eye(4)
                    
                    T_offset[0, 3] = 0.0      # X (ì¢Œìš°)
                    T_offset[1, 3] = 0.03    # Y (ìœ„ì•„ëž˜, ìœ„ê°€ -)
                    T_offset[2, 3] = -0.04    # Z (ì•žë’¤, ë’¤ê°€ -)
                    
                    # (4) ë§ˆì»¤ ìœ„ì¹˜ì— ì˜¤í”„ì…‹ì„ ê³±í•¨ -> ìµœì¢… ìž¡ì•„ì•¼ í•  ìœ„ì¹˜ (ì¹´ë©”ë¼ ê¸°ì¤€)
                    T_cam_target = T_cam_marker @ T_offset
                    
                    # ---------------------------------------------------------
                    
                    # UR10 ë² ì´ìŠ¤ í”„ë ˆìž„ ë³€í™˜ ì¤€ë¹„
                    target_frame = "base_link"
                    source_frame = "left_Camera" # TF íŠ¸ë¦¬ì— ë“±ë¡ëœ ì •í™•í•œ ì¹´ë©”ë¼ í”„ë ˆìž„ ì´ë¦„ í™•ì¸ í•„ìš”
                    
                    # PoseStamped ì„¤ì • (ìœ„ì—ì„œ ê³„ì‚°í•œ T_cam_target ì‚¬ìš©)
                    p_cam = PoseStamped()
                    p_cam.header.frame_id = source_frame
                    p_cam.header.stamp = msg.header.stamp
                    
                    p_cam.pose.position.x = T_cam_target[0, 3]
                    p_cam.pose.position.y = T_cam_target[1, 3]
                    p_cam.pose.position.z = T_cam_target[2, 3]
                    p_cam.pose.orientation.w = 1.0 # ìœ„ì¹˜ë§Œ ë³€í™˜í•  ê²ƒì´ë¯€ë¡œ íšŒì „ì€ ì¼ë‹¨ ë¬´ì‹œ

                    # TF ë³€í™˜: ì¹´ë©”ë¼ -> UR10 ë² ì´ìŠ¤
                    transform = self.tf_buffer.lookup_transform(
                        target_frame,
                        source_frame,
                        rclpy.time.Time(), 
                        timeout=rclpy.duration.Duration(seconds=0.1)
                    )
                    
                    # ì¢Œí‘œ ë³€í™˜ ìˆ˜í–‰
                    p_robot_pose = tf2_geometry_msgs.do_transform_pose(p_cam.pose, transform)
                    
                    info = MarkerInfo()
                    info.id = int(ids[i][0])
                    
                    # ë³€í™˜ëœ ì¢Œí‘œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì´ë¯¸ ë§ˆì»¤ ê¸°ì¤€ ì˜¤í”„ì…‹ì´ ì ìš©ë¨)
                    info.pose.position.x = p_robot_pose.position.x
                    info.pose.position.y = p_robot_pose.position.y
                    info.pose.position.z = p_robot_pose.position.z
                    
                    # ê·¸ë¦¬í¼ Orientation (í•­ìƒ ë°”ë‹¥ì„ ë³´ê±°ë‚˜ íŠ¹ì • ë°©í–¥ ê³ ì •)
                    # ì‚¬ìš©ìžê°€ ì„¤ì •í•œ ê³ ì •ê°’ ì‚¬ìš©
                    info.pose.orientation.x = self.default_quat[0]
                    info.pose.orientation.y = self.default_quat[1]
                    info.pose.orientation.z = self.default_quat[2]
                    info.pose.orientation.w = self.default_quat[3]
                    
                    marker_array.markers.append(info)

                    self.get_logger().info(f"ID {ids[i][0]}: Target(Base) -> X:{p_robot_pose.position.x:.3f}, Y:{p_robot_pose.position.y:.3f}, Z:{p_robot_pose.position.z:.3f}")

                except (tf2_ros.LookupException, tf2_ros.ExtrapolationException) as e:
                    self.get_logger().warn(f"TF Error: {e}")
                    continue
                
        cv2.imshow("Aruco View", frame)
        cv2.waitKey(1)

def main():
    rclpy.init()
    node = ArucoDetector()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        cv2.destroyAllWindows()
        rclpy.shutdown()

if __name__ == '__main__':
    main()