import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge
import cv2
import numpy as np
import tf2_ros
from geometry_msgs.msg import PoseStamped
from moma_interfaces.msg import MarkerArray, MarkerInfo
import tf2_geometry_msgs
from scipy.spatial.transform import Rotation
from std_msgs.msg import Bool

class ArucoDetector(Node):
    def __init__(self):
        super().__init__('aruco_detector_left')
        
        # ë§ˆì»¤ ë° ê²€ì¶œê¸° ì„¤ì • (OpenCV 4.7+ ëŒ€ì‘)
        self.marker_size = 0.13
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
        self.params = cv2.aruco.DetectorParameters()
        self.detector = cv2.aruco.ArucoDetector(self.aruco_dict, self.params)
        
        self.bridge = CvBridge()
        
        # TF ë¦¬ìŠ¤ë„ˆ
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)

        # ì¹´ë©”ë¼ êµ¬ë…
        self.create_subscription(Image, '/front_stereo_camera/left/image_raw', self.image_callback, 10)
        self.create_subscription(CameraInfo, '/front_stereo_camera/left/camera_info', self.info_callback, 10)
        
        # RMPFlow íƒ€ê²Ÿ í¼ë¸”ë¦¬ì…”(ë””ë²„ê¹…ìš©)
        # self.pose_pub = self.create_publisher(PoseStamped, '/rmp_target_pose', 10)
        
        # [On/Off ìŠ¤ìœ„ì¹˜] ì™¸ë¶€ì—ì„œ Trueë¥¼ ë³´ë‚´ë©´ ê²€ì¶œ ì‹œìž‘
        self.create_subscription(Bool, '/vision/enable_left', self.enable_callback, 10)
        
        # [ê²°ê³¼ ì†¡ì‹ ] ì§ì ‘ ì œì–´(/rmp_target_pose) ëŒ€ì‹  ì •ë³´ë§Œ ì œê³µ
        self.result_pub = self.create_publisher(MarkerArray, '/vision/left_markers', 10)
        
        # ìƒíƒœ ë³€ìˆ˜
        self.is_enabled = False  # ê¸°ë³¸ê°’: êº¼ì§
        
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # ê·¸ë¦¬í¼ê°€ ë°”ë‹¥ì„ í–¥í•˜ëŠ” orientation
        euler = np.array([0, np.pi/2, 0])  # roll, pitch, yaw
        rot = Rotation.from_euler('xyz', euler)
        self.default_quat = rot.as_quat()  # [x, y, z, w]
        
        self.get_logger().info("âœ… Front Camera Detector Ready (Waiting for Enable Signal...)")
        
    
    def enable_callback(self, msg):
        """On/Off ìŠ¤ìœ„ì¹˜ ì½œë°±"""
        if msg.data and not self.is_enabled:
            self.get_logger().info("ðŸŸ¢ Detector STARTED")
            self.is_enabled = True
        elif not msg.data and self.is_enabled:
            self.get_logger().info("ðŸ”´ Detector STOPPED")
            self.is_enabled = False

    def info_callback(self, msg):
        if self.camera_matrix is None:
            self.camera_matrix = np.array(msg.k).reshape((3, 3))
            self.dist_coeffs = np.array(msg.d)

    def image_callback(self, msg):
        # 1. êº¼ì ¸ìžˆê±°ë‚˜ ì¹´ë©”ë¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
        if not self.is_enabled or self.camera_matrix is None:
            return

        try:
            frame = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except: return

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        corners, ids, rejected = self.detector.detectMarkers(gray)

        if ids is not None:
            # ë³´ë‚¼ ë©”ì‹œì§€ ê°ì²´ ìƒì„±
            marker_array = MarkerArray()
            marker_array.header.stamp = self.get_clock().now().to_msg()
            marker_array.header.frame_id = "base_link" # ìµœì¢… ì¢Œí‘œê³„ ê¸°ì¤€
            
            # 3D ì¢Œí‘œ ê³„ì‚°ì„ ìœ„í•œ ë§ˆì»¤ ì •ì˜
            marker_half = self.marker_size / 2.0
            obj_points = np.array([
                [-marker_half, marker_half, 0],
                [marker_half, marker_half, 0],
                [marker_half, -marker_half, 0],
                [-marker_half, -marker_half, 0]
            ], dtype=np.float32)

            # ëª¨ë“  ê²€ì¶œëœ ë§ˆì»¤ì— ëŒ€í•´ ìˆ˜í–‰
            for i in range(len(ids)):
                current_id = int(ids[i][0])
                # solvePnPë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë§ˆì»¤ì˜ í¬ì¦ˆ ê³„ì‚°
                _, rvec, tvec = cv2.solvePnP(
                    obj_points, 
                    corners[i][0], 
                    self.camera_matrix, 
                    self.dist_coeffs
                )

                # ì‹œê°í™” ì²˜ë¦¬ (ì°¨ì› ë¬¸ì œë¡œ ì¸í•´ rvec, tvec í˜•íƒœ ì£¼ì˜)
                cv2.aruco.drawDetectedMarkers(frame, corners, ids)
                cv2.drawFrameAxes(frame, self.camera_matrix, self.dist_coeffs, rvec, tvec, 0.1)

                try:
                    # UR10 ë² ì´ìŠ¤ í”„ë ˆìž„ (RMPFlowê°€ ì‚¬ìš©í•˜ëŠ” ì¢Œí‘œê³„)
                    target_frame = "base_link"
                    source_frame = "front_stereo_camera_left_rgb"
                    
                    # PoseStamped ì„¤ì • (ì¹´ë©”ë¼ ì¢Œí‘œê³„)
                    p_cam = PoseStamped()
                    p_cam.header.frame_id = source_frame
                    p_cam.header.stamp = msg.header.stamp
                    
                    # tvecì€ (3, 1) í˜•íƒœì´ë¯€ë¡œ ì¸ë±ì‹± ì£¼ì˜
                    p_cam.pose.position.x = float(tvec[0][0])
                    p_cam.pose.position.y = float(tvec[1][0])
                    p_cam.pose.position.z = float(tvec[2][0])
                    p_cam.pose.orientation.w = 1.0

                    # TF ë³€í™˜: ì¹´ë©”ë¼ -> UR10 ë² ì´ìŠ¤
                    transform = self.tf_buffer.lookup_transform(
                        target_frame,
                        source_frame,
                        rclpy.time.Time(), 
                        timeout=rclpy.duration.Duration(seconds=0.1)
                    )
                    
                    # ì¢Œí‘œ ë³€í™˜
                    p_robot_pose = tf2_geometry_msgs.do_transform_pose(p_cam.pose, transform)
                    
                    info = MarkerInfo()
                    info.id = int(ids[i][0]) # ë§ˆì»¤ ID ì €ìž¥
                    
                    # ë¬¼ì²´ ì§‘ê¸°ìš© ì¢Œí‘œ ì˜¤í”„ì…‹ ì ìš©
                    robot_x = p_robot_pose.position.x
                    robot_y = p_robot_pose.position.y + 0.04 
                    robot_z = p_robot_pose.position.z + 0.04
                    
                    # Pose ì±„ìš°ê¸°
                    info.pose.position.x = robot_x
                    info.pose.position.y = robot_y
                    info.pose.position.z = robot_z
                    
                    # Orientationì€ ê¸°ì¡´ self.default_quat ê°’ ì‚¬ìš©
                    info.pose.orientation.x = self.default_quat[0]
                    info.pose.orientation.y = self.default_quat[1]
                    info.pose.orientation.z = self.default_quat[2]
                    info.pose.orientation.w = self.default_quat[3]
                    
                    # ë°°ì—´ì— ì¶”ê°€
                    marker_array.markers.append(info)

                    self.get_logger().info(f"ID {ids[i][0]}: Robot Base -> X:{robot_x:.3f}, Y:{robot_y:.3f}, Z:{robot_z:.3f}")

                except (tf2_ros.LookupException, tf2_ros.ExtrapolationException) as e:
                    continue

            # [ì¶”ê°€ë¨] ë£¨í”„ê°€ ëë‚œ í›„ í•œ ë²ˆì— ì „ì†¡
            if len(marker_array.markers) > 0:
                self.result_pub.publish(marker_array)
                
        cv2.imshow("Aruco View", frame)
        cv2.waitKey(1)

def main():
    rclpy.init()
    node = ArucoDetector()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        cv2.destroyAllWindows()
        rclpy.shutdown()

if __name__ == '__main__':
    main()