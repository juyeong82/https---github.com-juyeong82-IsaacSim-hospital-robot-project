import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge
import cv2
import numpy as np
import tf2_ros
from geometry_msgs.msg import PoseStamped
from moma_interfaces.msg import MarkerArray, MarkerInfo
import tf2_geometry_msgs
from scipy.spatial.transform import Rotation
from std_msgs.msg import Bool
from tf2_ros import Time


class ArucoDetector(Node):
    def __init__(self):
        super().__init__('aruco_detector_left')
        
        self.use_debug_offset = False
        
        # [ìˆ˜ì •] ë§ˆì»¤ ë° ê²€ì¶œê¸° ì„¤ì • (OpenCV 4.7+ ëŒ€ì‘)
        self.marker_size = 0.13
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
        
        # 1. íŒŒë¼ë¯¸í„° ìƒì„±ìž ë³€ê²½ (_create í•¨ìˆ˜ ì‚­ì œë¨)
        self.params = cv2.aruco.DetectorParameters()
        
        # 2. ArucoDetector ê°ì²´ ìƒì„± (ê²€ì¶œ ì†ë„ ë° ìµœì í™” ìœ ë¦¬)
        self.detector = cv2.aruco.ArucoDetector(self.aruco_dict, self.params)
        
        self.bridge = CvBridge()
        
        # TF ë¦¬ìŠ¤ë„ˆ
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)

        # ì¹´ë©”ë¼ êµ¬ë…
        self.create_subscription(Image, '/left_camera/rgb', self.image_callback, 10)
        self.create_subscription(CameraInfo, '/left_camera/camera_info', self.info_callback, 10)
        
        # RMPFlow íƒ€ê²Ÿ í¼ë¸”ë¦¬ì…”(ë””ë²„ê¹…ìš©)
        # self.pose_pub = self.create_publisher(PoseStamped, '/rmp_target_pose', 10)
        
        # [On/Off ìŠ¤ìœ„ì¹˜] ì™¸ë¶€ì—ì„œ Trueë¥¼ ë³´ë‚´ë©´ ê²€ì¶œ ì‹œìž‘
        self.create_subscription(Bool, '/vision/enable_left', self.enable_callback, 10)
        
        # [ê²°ê³¼ ì†¡ì‹ ] ì§ì ‘ ì œì–´(/rmp_target_pose) ëŒ€ì‹  ì •ë³´ë§Œ ì œê³µ
        self.result_pub = self.create_publisher(MarkerArray, '/vision/left_markers', 10)
        
        # ìƒíƒœ ë³€ìˆ˜
        self.is_enabled = False  # ê¸°ë³¸ê°’: êº¼ì§
        
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # ê·¸ë¦¬í¼ê°€ ë°”ë‹¥ì„ í–¥í•˜ëŠ” orientation (ì›ëž˜ ì½”ë“œì™€ ë™ì¼)
        euler = np.array([0, np.pi/2, 0])  # roll, pitch, yaw
        rot = Rotation.from_euler('xyz', euler)
        self.default_quat = rot.as_quat()  # [x, y, z, w]
        
        self.get_logger().info("âœ… Left Camera Detector Ready (Waiting for Enable Signal...)")
        
    
    def enable_callback(self, msg):
        """On/Off ìŠ¤ìœ„ì¹˜ ì½œë°± (ì°½ ì œì–´ ë¡œì§ ì¶”ê°€)"""
        # 1. ì¼œëŠ” ì‹ í˜¸ (False -> True)
        if msg.data and not self.is_enabled:
            self.get_logger().info("ðŸŸ¢ Detector STARTED")
            self.is_enabled = True
            # ë³„ë„ì˜ ì°½ ìƒì„± ì½”ë“œëŠ” í•„ìš” ì—†ìŒ 
            # (ì´í›„ image_callbackì´ ëŒë©´ì„œ cv2.imshowê°€ í˜¸ì¶œë˜ë©´ ì°½ì´ ìžë™ìœ¼ë¡œ ëœ¸)

        # 2. ë„ëŠ” ì‹ í˜¸ (True -> False)
        elif not msg.data and self.is_enabled:
            self.get_logger().info("ðŸ”´ Detector STOPPED")
            self.is_enabled = False
            
            # [í•µì‹¬] ë¦¬ì†ŒìŠ¤ ì ˆì•½ì„ ìœ„í•´ ì—´ë ¤ìžˆëŠ” ëª¨ë“  OpenCV ì°½ì„ ì¦‰ì‹œ ë‹«ìŒ
            cv2.destroyAllWindows()
    def info_callback(self, msg):
        if self.camera_matrix is None:
            self.camera_matrix = np.array(msg.k).reshape((3, 3))
            self.dist_coeffs = np.array(msg.d)

    def image_callback(self, msg):
        # 1. êº¼ì ¸ìžˆê±°ë‚˜ ì¹´ë©”ë¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
        if not self.is_enabled or self.camera_matrix is None:
            return

        try:
            frame = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except: return

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        corners, ids, rejected = self.detector.detectMarkers(gray)

        if ids is not None:
            # ë³´ë‚¼ ë©”ì‹œì§€ ê°ì²´ ìƒì„±
            marker_array = MarkerArray()
            marker_array.header.stamp = self.get_clock().now().to_msg()
            marker_array.header.frame_id = "base_link" # ìµœì¢… ì¢Œí‘œê³„ ê¸°ì¤€
            
            # 3D ì¢Œí‘œ ê³„ì‚°ì„ ìœ„í•œ ë§ˆì»¤ ì •ì˜
            marker_half = self.marker_size / 2.0
            obj_points = np.array([
                [-marker_half, marker_half, 0],
                [marker_half, marker_half, 0],
                [marker_half, -marker_half, 0],
                [-marker_half, -marker_half, 0]
            ], dtype=np.float32)

            # ëª¨ë“  ê²€ì¶œëœ ë§ˆì»¤ì— ëŒ€í•´ ìˆ˜í–‰
            for i in range(len(ids)):
                current_id = int(ids[i][0])
                # solvePnPë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë§ˆì»¤ì˜ í¬ì¦ˆ ê³„ì‚°
                _, rvec, tvec = cv2.solvePnP(
                    obj_points, 
                    corners[i][0], 
                    self.camera_matrix, 
                    self.dist_coeffs
                )

                # ì‹œê°í™” ì²˜ë¦¬ (ì°¨ì› ë¬¸ì œë¡œ ì¸í•´ rvec, tvec í˜•íƒœ ì£¼ì˜)
                cv2.aruco.drawDetectedMarkers(frame, corners, ids)
                cv2.drawFrameAxes(frame, self.camera_matrix, self.dist_coeffs, rvec, tvec, 0.1)

                try:
                    # ---------------------------------------------------------
                    # [ìˆ˜ì •] ë¡œì»¬ ì˜¤í”„ì…‹ ì ìš©ì„ ìœ„í•œ í–‰ë ¬ ì—°ì‚°
                    # ---------------------------------------------------------
                    
                    # (1) rvec(íšŒì „ë²¡í„°) -> R(3x3 íšŒì „í–‰ë ¬) ë³€í™˜
                    R, _ = cv2.Rodrigues(rvec)
                    
                    # (2) ë§ˆì»¤ì˜ ë³€í™˜ í–‰ë ¬ (4x4) ìƒì„± (ì¹´ë©”ë¼ ê¸°ì¤€ ë§ˆì»¤ ìœ„ì¹˜)
                    T_cam_marker = np.eye(4)
                    T_cam_marker[:3, :3] = R
                    T_cam_marker[:3, 3] = tvec.squeeze()
                    
                    # (3) ì˜¤í”„ì…‹ í–‰ë ¬ ìƒì„± (ë§ˆì»¤ ê¸°ì¤€ ë¡œì»¬ ì˜¤í”„ì…‹)
                    # OpenCV Aruco ì¢Œí‘œê³„ ê¸°ì¤€: X(ìš°), Y(í•˜), Z(ì „ë°©)
                    # ëª©í‘œ: ë§ˆì»¤ ë’¤ìª½(íŠœë¸Œ ì¤‘ì‹¬) + ë§ˆì»¤ ìœ„ìª½(íŠœë¸Œ ìƒë‹¨)
                    T_offset = np.eye(4)
                    
                    # í”Œëž˜ê·¸ì— ë”°ë¥¸ ì˜¤í”„ì…‹ ì ìš© ë¶„ê¸°
                    if self.use_debug_offset:
                        # ë””ë²„ê¹… ëª¨ë“œ: ê·¸ë¦¬í¼ê°€ ìž¡ì•„ì•¼ í•  ìœ„ì¹˜ë¡œ ë³€í™˜í•´ì„œ ë³´ëƒ„
                        T_offset[0, 3] = 0.0      # X (ì¢Œìš°)
                        T_offset[1, 3] = 0.03     # Y (ìœ„ì•„ëž˜)
                        T_offset[2, 3] = -0.04    # Z (ì•žë’¤)
                    else:
                        # Raw ë°ì´í„° ëª¨ë“œ: ë§ˆì»¤ì˜ ì •ì¤‘ì•™(ì›ì ) ì¢Œí‘œë¥¼ ê·¸ëŒ€ë¡œ ë³´ëƒ„
                        # (Identity Matrix ìœ ì§€ -> ì˜¤í”„ì…‹ 0)
                        pass
                    
                    # (4) ë§ˆì»¤ ìœ„ì¹˜ì— ì˜¤í”„ì…‹ì„ ê³±í•¨ -> ìµœì¢… ìž¡ì•„ì•¼ í•  ìœ„ì¹˜ (ì¹´ë©”ë¼ ê¸°ì¤€)
                    T_cam_target = T_cam_marker @ T_offset
                    
                    # ---------------------------------------------------------
                    
                    # UR10 ë² ì´ìŠ¤ í”„ë ˆìž„ ë³€í™˜ ì¤€ë¹„
                    target_frame = "base_link"
                    source_frame = "left_Camera" # TF íŠ¸ë¦¬ì— ë“±ë¡ëœ ì •í™•í•œ ì¹´ë©”ë¼ í”„ë ˆìž„ ì´ë¦„ í™•ì¸ í•„ìš”
                    
                    # PoseStamped ì„¤ì • (ì¹´ë©”ë¼ ì¢Œí‘œê³„)
                    p_cam = PoseStamped()
                    p_cam.header.frame_id = source_frame
                    p_cam.header.stamp = rclpy.time.Time(seconds=0).to_msg()
                    
                    # ê³„ì‚°ëœ T_cam_targetì—ì„œ ìœ„ì¹˜ ì¶”ì¶œ
                    p_cam.pose.position.x = T_cam_target[0, 3]
                    p_cam.pose.position.y = T_cam_target[1, 3]
                    p_cam.pose.position.z = T_cam_target[2, 3]
                    p_cam.pose.orientation.w = 1.0
                    
                    # íšŒì „ ì¶”ì¶œ (ì¹´ë©”ë¼ ê¸°ì¤€ ë§ˆì»¤ì˜ íšŒì „)
                    q_cam = Rotation.from_matrix(T_cam_target[:3, :3]).as_quat()
                    p_cam.pose.orientation.x = q_cam[0]
                    p_cam.pose.orientation.y = q_cam[1]
                    p_cam.pose.orientation.z = q_cam[2]
                    p_cam.pose.orientation.w = q_cam[3]
                    
                    # ì¢Œí‘œ ë³€í™˜
                    p_robot_pose_stamped = self.tf_buffer.transform(
                        p_cam, 
                        target_frame, # "base_link"
                        timeout=rclpy.duration.Duration(seconds=0.1)
                    )
                    
                    info = MarkerInfo()
                    info.id = int(ids[i][0]) # ë§ˆì»¤ ID ì €ìž¥
                    
                    # ë³€í™˜ëœ ì¢Œí‘œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì´ë¯¸ ë§ˆì»¤ ê¸°ì¤€ ì˜¤í”„ì…‹ ì ìš©ë¨)
                    info.pose = p_robot_pose_stamped.pose
                    
                    # ë°°ì—´ì— ì¶”ê°€
                    marker_array.markers.append(info)

                    self.get_logger().info(f"ID {ids[i][0]}: Transformed Pose -> {info.pose.position.x:.3f}, {info.pose.position.y:.3f}, {info.pose.position.z:.3f}")
                    
                except (tf2_ros.LookupException, tf2_ros.ExtrapolationException) as e:
                    self.get_logger().warn(f"TF Error: {e}")
                    continue
                
            # [ì¶”ê°€ë¨] ë£¨í”„ê°€ ëë‚œ í›„ í•œ ë²ˆì— ì „ì†¡
            if len(marker_array.markers) > 0:
                self.result_pub.publish(marker_array)
                
        cv2.imshow("Aruco View", frame)
        cv2.waitKey(1)

def main():
    rclpy.init()
    node = ArucoDetector()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        cv2.destroyAllWindows()
        rclpy.shutdown()

if __name__ == '__main__':
    main()