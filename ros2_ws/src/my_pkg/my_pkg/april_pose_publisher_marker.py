#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from apriltag_msgs.msg import AprilTagDetectionArray
from sensor_msgs.msg import CameraInfo
from geometry_msgs.msg import PoseStamped
import cv2
import numpy as np
from cv_bridge import CvBridge
from sensor_msgs.msg import Image
from std_msgs.msg import Bool

class DockPosePublisher(Node):
    def __init__(self):
        super().__init__('dock_pose_publisher')
        
        self.target_id = 4       
        self.tag_size = 0.25     # íƒœê·¸ í¬ê¸° 25cm
        
        # [ì¶”ê°€] object_pointsëŠ” ë³€í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì´ˆê¸°í™” ë•Œ í•œ ë²ˆë§Œ ì„ ì–¸ (ìµœì í™” í•µì‹¬)
        s = self.tag_size / 2.0
        self.object_points = np.array([
            [-s, -s, 0], [ s, -s, 0],
            [ s,  s, 0], [-s,  s, 0]
        ], dtype=np.float32)

        self.camera_matrix = None
        self.dist_coeffs = None
        
        self.create_subscription(CameraInfo, '/front_camera/camera_info', self.camera_info_callback, 10)
        self.create_subscription(AprilTagDetectionArray, '/detections', self.detection_callback, 10)
        self.publisher = self.create_publisher(PoseStamped, 'detected_dock_pose', 10)
        
        self.get_logger().info(f"ğŸš€ Dock Pose Publisher Started (Target ID: {self.target_id})")
        
        self.bridge = CvBridge()
        self.latest_image = None
        
        # ë””ë²„ê¹… ëª¨ë“œ ì„¤ì • (Trueì¼ ë•Œë§Œ í™”ë©´ ë„ì›€)
        self.SHOW_DEBUG_IMAGE = True 
        
        # ì´ˆê¸° ìƒíƒœëŠ” ë¹„í™œì„±í™” (Docking ë…¸ë“œê°€ ì¼œì¤˜ì•¼ ì‘ë™)
        self.is_active = False
        
        self.create_subscription(Image, '/front_camera/rgb', self.image_callback, 10)     
        
        # í™œì„±í™”/ë¹„í™œì„±í™” íŠ¸ë¦¬ê±° êµ¬ë…
        self.create_subscription(Bool, '/docking/trigger', self.trigger_callback, 10)   

    # [ì¶”ê°€] ë„í‚¹ ë…¸ë“œì—ì„œ ë³´ë‚´ëŠ” ì‹ í˜¸(True/False)ë¥¼ ë°›ì•„ ìƒíƒœ ë³€ê²½
    def trigger_callback(self, msg):
        self.is_active = msg.data
        status = "ON" if self.is_active else "OFF"
        self.get_logger().info(f"ğŸ”„ Tracking Status Changed: {status}")
        
        # ë¹„í™œì„±í™” ì‹ í˜¸ë¥¼ ë°›ìœ¼ë©´ ì¦‰ì‹œ ì°½ ë‹«ê¸°
        if not self.is_active:
            cv2.destroyAllWindows()
        
    def image_callback(self, msg):
        try:
            # ROS Image -> OpenCV Image ë³€í™˜ (ë¶€í•˜ ì ìŒ)
            self.latest_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except Exception as e:
            self.get_logger().error(f"Image conversion failed: {e}")
    
    # ---------------------------------------------------------
    # íšŒì „ í–‰ë ¬ì„ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    # ---------------------------------------------------------
    def get_quaternion_from_rotation_matrix(self, R):
        sy = np.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])
        singular = sy < 1e-6

        if not singular:
            x = np.arctan2(R[2, 1], R[2, 2])
            y = np.arctan2(-R[2, 0], sy)
            z = np.arctan2(R[1, 0], R[0, 0])
        else:
            x = np.arctan2(-R[1, 2], R[1, 1])
            y = np.arctan2(-R[2, 0], sy)
            z = 0

        # Euler (x, y, z) -> Quaternion (x, y, z, w)
        cy = np.cos(z * 0.5)
        sy = np.sin(z * 0.5)
        cp = np.cos(y * 0.5)
        sp = np.sin(y * 0.5)
        cr = np.cos(x * 0.5)
        sr = np.sin(x * 0.5)

        q_w = cr * cp * cy + sr * sp * sy
        q_x = sr * cp * cy - cr * sp * sy
        q_y = cr * sp * cy + sr * cp * sy
        q_z = cr * cp * sy - sr * sp * cy
        
        return q_x, q_y, q_z, q_w

    def camera_info_callback(self, msg):
        if self.camera_matrix is None:
            self.camera_matrix = np.array(msg.k).reshape((3, 3))
            self.dist_coeffs = np.array(msg.d)
            self.get_logger().info("âœ… Camera Info Received!")

    def detection_callback(self, msg):
        # [ìˆ˜ì •] ì¹´ë©”ë¼ ì •ë³´ê°€ ì—†ê±°ë‚˜, ë¹„í™œì„±í™”(is_active=False) ìƒíƒœë©´ ì¦‰ì‹œ ë¦¬í„´
        if self.camera_matrix is None or not self.is_active:
            return
        
        # ì‹œê°í™”ìš© ì´ë¯¸ì§€ ë³µì‚¬ (ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ í™”ë©´ ìƒì„± ë°©ì§€)
        debug_image = self.latest_image.copy() if (self.latest_image is not None and self.SHOW_DEBUG_IMAGE) else None

        for detection in msg.detections:
            det_id = detection.id[0] if isinstance(detection.id, (list, tuple)) else detection.id
            
            if det_id == self.target_id:
                image_points = np.array([
                    [detection.corners[0].x, detection.corners[0].y],
                    [detection.corners[1].x, detection.corners[1].y],
                    [detection.corners[2].x, detection.corners[2].y],
                    [detection.corners[3].x, detection.corners[3].y]
                ], dtype=np.float32)

                # s = self.tag_size / 2.0
                # object_points = np.array([
                #     [-s, -s, 0], [ s, -s, 0],
                #     [ s,  s, 0], [-s,  s, 0]
                # ], dtype=np.float32)

                success, rvec, tvec = cv2.solvePnP(
                    self.object_points, 
                    image_points, 
                    self.camera_matrix, 
                    self.dist_coeffs
                )

                if success:
                    # Translation & Rotation
                    raw_x, raw_y, raw_z = tvec[0][0], tvec[1][0], tvec[2][0]
                    # rvec -> Rotation Matrix
                    R, _ = cv2.Rodrigues(rvec)

                    # Quaternion ë³€í™˜ (Publisherìš©)
                    
                    # ë¡œê·¸ ì¶œë ¥ì„ ìœ„í•´ ì˜¤ì¼ëŸ¬ ê°ë„ ë³„ë„ ê³„ì‚°
                    sy = np.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])
                    singular = sy < 1e-6

                    if not singular:
                        eul_x = np.arctan2(R[2, 1], R[2, 2])
                        eul_y = np.arctan2(-R[2, 0], sy)
                        eul_z = np.arctan2(R[1, 0], R[0, 0])
                    else:
                        eul_x = np.arctan2(-R[1, 2], R[1, 1])
                        eul_y = np.arctan2(-R[2, 0], sy)
                        eul_z = 0
                    
                    # ë¼ë””ì•ˆ -> ë„(Degree) ë³€í™˜
                    deg_x = np.degrees(eul_x)
                    deg_y = np.degrees(eul_y)
                    deg_z = np.degrees(eul_z)

                    # Matrix -> Quaternion
                    qx, qy, qz, qw = self.get_quaternion_from_rotation_matrix(R)

                    # Pose Publish
                    pose_msg = PoseStamped()
                    pose_msg.header.frame_id = "Camera"
                    pose_msg.header.stamp = self.get_clock().now().to_msg()
                    
                    pose_msg.pose.position.x = raw_x
                    pose_msg.pose.position.y = raw_y
                    pose_msg.pose.position.z = raw_z

                    # ê³„ì‚°ëœ ì¿¼í„°ë‹ˆì–¸ ì…ë ¥
                    pose_msg.pose.orientation.x = qx
                    pose_msg.pose.orientation.y = qy
                    pose_msg.pose.orientation.z = qz
                    pose_msg.pose.orientation.w = qw
                    
                    self.publisher.publish(pose_msg)
                    
                    # [ë¡œê·¸ ìˆ˜ì •] ê°ë„(Degree) ì •ë³´ í¬í•¨ (Yì¶• íšŒì „ì´ ì£¼ë¡œ Yawì„)
                    self.get_logger().info(
                        f"ğŸ” [TRACKING] ID:{self.target_id} | Dist:{raw_z:4.2f}m | "
                        f"Deg X:{deg_x:6.2f} Y:{deg_y:6.2f} Z:{deg_z:6.2f}",
                        throttle_duration_sec=0.5
                    )
                    self.last_detection_time = self.get_clock().now()
                    
                    # ì €ë¶€í•˜ ì‹œê°í™” (Low-Overhead Visualization)
                    if self.SHOW_DEBUG_IMAGE and debug_image is not None:
                        # ì¢Œí‘œì¶• ê·¸ë¦¬ê¸° (ê¸¸ì´ 0.15m) -> X:ë¹¨ê°•, Y:ì´ˆë¡, Z:íŒŒë‘ ìë™ ìƒì„±
                        cv2.drawFrameAxes(debug_image, self.camera_matrix, self.dist_coeffs, rvec, tvec, 0.15)
                        
                        # ìƒíƒœ í…ìŠ¤íŠ¸ í‘œì‹œ (ê±°ë¦¬, Yaw ê°ë„ ë“±)
                        yaw_deg = deg_y
                        
                        info_text = f"ID:{det_id} Dist:{raw_z:.2f}m Yaw:{yaw_deg:.1f}deg"
                        
                        # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ (ê°€ë…ì„±)
                        cv2.rectangle(debug_image, (10, 10), (450, 40), (0, 0, 0), -1)
                        cv2.putText(debug_image, info_text, (20, 32), 
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                        
                        # ë§ˆì»¤ í…Œë‘ë¦¬ (ë…¹ìƒ‰)
                        pts = image_points.astype(int).reshape((-1, 1, 2))
                        cv2.polylines(debug_image, [pts], True, (0, 255, 0), 2)
        
        # í™”ë©´ í‘œì‹œ (ì´ë¯¸ì§€ê°€ ìˆì„ ë•Œë§Œ 1ms ëŒ€ê¸°)
        if debug_image is not None:
            cv2.imshow("Docking Debug", debug_image)
            cv2.waitKey(1)

def main(args=None):
    rclpy.init(args=args)
    node = DockPosePublisher()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()