import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge
import cv2
import numpy as np
import tf2_ros
from geometry_msgs.msg import PoseStamped
from moma_interfaces.msg import MarkerArray, MarkerInfo
import tf2_geometry_msgs
from scipy.spatial.transform import Rotation
from std_msgs.msg import Bool
import math
from collections import deque

class ArucoDetector(Node):
    def __init__(self):
        super().__init__('aruco_detector_front')
        
        # [ìˆ˜ì •] ë§ˆì»¤ ë° ê²€ì¶œê¸° ì„¤ì • (OpenCV 4.7+ ëŒ€ì‘)
        self.marker_size = 0.13
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
        
        # 1. íŒŒë¼ë¯¸í„° ìƒì„±ìž ë³€ê²½ (_create í•¨ìˆ˜ ì‚­ì œë¨)
        self.params = cv2.aruco.DetectorParameters()
        
        # 2. ArucoDetector ê°ì²´ ìƒì„± (ê²€ì¶œ ì†ë„ ë° ìµœì í™” ìœ ë¦¬)
        self.detector = cv2.aruco.ArucoDetector(self.aruco_dict, self.params)
        
        self.bridge = CvBridge()
        
        # TF ë¦¬ìŠ¤ë„ˆ
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)

        # ì¹´ë©”ë¼ êµ¬ë…
        self.create_subscription(Image, '/front_camera/rgb', self.image_callback, 10)
        self.create_subscription(CameraInfo, '/front_camera/camera_info', self.info_callback, 10)
        
        # [On/Off ìŠ¤ìœ„ì¹˜] ì™¸ë¶€ì—ì„œ Trueë¥¼ ë³´ë‚´ë©´ ê²€ì¶œ ì‹œìž‘
        self.create_subscription(Bool, '/vision/enable_front', self.enable_callback, 10)
        
        # [ê²°ê³¼ ì†¡ì‹ ] ì§ì ‘ ì œì–´(/rmp_target_pose) ëŒ€ì‹  ì •ë³´ë§Œ ì œê³µ
        self.result_pub = self.create_publisher(MarkerArray, '/vision/front_markers', 10)
        
        # ìƒíƒœ ë³€ìˆ˜
        self.is_enabled = False  # ê¸°ë³¸ê°’: êº¼ì§
        
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # =========================================================
        # [ì¶”ê°€] Yaw ì˜¤í”„ì…‹ ì„¤ì •
        # =========================================================
        self.yaw_offset = 90.0  # -90Â°ë¥¼ 0Â°ë¡œ ë§Œë“¤ê¸° ìœ„í•œ ì˜¤í”„ì…‹
        # =========================================================
        
        # =========================================================
        # [ì¶”ê°€] ìŠ¤ë¬´ë”© í•„í„° (ì´ë™ í‰ê· )
        # =========================================================
        self.marker_history = {}  # {marker_id: deque of (x, y, z, yaw)}
        self.history_size = 5     # ìµœê·¼ 5í”„ë ˆìž„ í‰ê· 
        # =========================================================
        
        # ê·¸ë¦¬í¼ê°€ ë°”ë‹¥ì„ í–¥í•˜ëŠ” orientation (ì›ëž˜ ì½”ë“œì™€ ë™ì¼)
        euler = np.array([0, np.pi/2, 0])  # roll, pitch, yaw
        rot = Rotation.from_euler('xyz', euler)
        self.default_quat = rot.as_quat()  # [x, y, z, w]
        
        self.get_logger().info("âœ… Front Camera Detector Ready (with Smoothing)")
        self.get_logger().info(f"ðŸ”§ Yaw Offset: {self.yaw_offset}Â° | History Size: {self.history_size}")
        
    
    def enable_callback(self, msg):
        """On/Off ìŠ¤ìœ„ì¹˜ ì½œë°±"""
        if msg.data and not self.is_enabled:
            self.get_logger().info("ðŸŸ¢ Detector STARTED")
            self.is_enabled = True
        elif not msg.data and self.is_enabled:
            self.get_logger().info("ðŸ”´ Detector STOPPED")
            self.is_enabled = False

    def info_callback(self, msg):
        if self.camera_matrix is None:
            self.camera_matrix = np.array(msg.k).reshape((3, 3))
            self.dist_coeffs = np.array(msg.d)

    def smooth_pose(self, marker_id, x, y, z, yaw):
        """ìœ„ì¹˜ ë° ê°ë„ ìŠ¤ë¬´ë”©"""
        if marker_id not in self.marker_history:
            self.marker_history[marker_id] = deque(maxlen=self.history_size)
        
        self.marker_history[marker_id].append((x, y, z, yaw))
        
        # í‰ê·  ê³„ì‚°
        history = list(self.marker_history[marker_id])
        avg_x = sum(h[0] for h in history) / len(history)
        avg_y = sum(h[1] for h in history) / len(history)
        avg_z = sum(h[2] for h in history) / len(history)
        
        # Yaw ê°ë„ discontinuity ì²˜ë¦¬
        yaws = [h[3] for h in history]
        normalized_yaws = [yaws[0]]
        for y in yaws[1:]:
            diff = y - yaws[0]
            while diff > 180: diff -= 360
            while diff < -180: diff += 360
            normalized_yaws.append(yaws[0] + diff)
        
        avg_yaw = sum(normalized_yaws) / len(normalized_yaws)
        
        # -180~180 ì •ê·œí™”
        while avg_yaw > 180: avg_yaw -= 360
        while avg_yaw < -180: avg_yaw += 360
        
        return avg_x, avg_y, avg_z, avg_yaw

    def image_callback(self, msg):
        # 1. êº¼ì ¸ìžˆê±°ë‚˜ ì¹´ë©”ë¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
        if not self.is_enabled or self.camera_matrix is None:
            return

        try:
            frame = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except: return

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        corners, ids, rejected = self.detector.detectMarkers(gray)

        if ids is not None:
            # ë³´ë‚¼ ë©”ì‹œì§€ ê°ì²´ ìƒì„±
            marker_array = MarkerArray()
            marker_array.header.stamp = self.get_clock().now().to_msg()
            marker_array.header.frame_id = "base_link" # ìµœì¢… ì¢Œí‘œê³„ ê¸°ì¤€
            
            # 3D ì¢Œí‘œ ê³„ì‚°ì„ ìœ„í•œ ë§ˆì»¤ ì •ì˜
            marker_half = self.marker_size / 2.0
            obj_points = np.array([
                [-marker_half, marker_half, 0],
                [marker_half, marker_half, 0],
                [marker_half, -marker_half, 0],
                [-marker_half, -marker_half, 0]
            ], dtype=np.float32)

            # ëª¨ë“  ê²€ì¶œëœ ë§ˆì»¤ì— ëŒ€í•´ ìˆ˜í–‰
            for i in range(len(ids)):
                current_id = int(ids[i][0])
                # solvePnPë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë§ˆì»¤ì˜ í¬ì¦ˆ ê³„ì‚°
                _, rvec, tvec = cv2.solvePnP(
                    obj_points, 
                    corners[i][0], 
                    self.camera_matrix, 
                    self.dist_coeffs
                )

                # ì‹œê°í™” ì²˜ë¦¬
                cv2.aruco.drawDetectedMarkers(frame, corners, ids)
                cv2.drawFrameAxes(frame, self.camera_matrix, self.dist_coeffs, rvec, tvec, 0.1)

                try:
                    target_frame = "base_link"
                    source_frame = "Camera"

                    # íšŒì „ ë²¡í„° -> íšŒì „ í–‰ë ¬
                    R_mat, _ = cv2.Rodrigues(rvec)
                    
                    # ì¹´ë©”ë¼ ê¸°ì¤€ ë§ˆì»¤ ë³€í™˜ í–‰ë ¬
                    T_cam_marker = np.eye(4)
                    T_cam_marker[:3, :3] = R_mat
                    T_cam_marker[:3, 3] = tvec.squeeze()
                    
                    # ì˜¤í”„ì…‹ (í•„ìš”ì‹œ ì¡°ì •)
                    T_offset = np.eye(4)
                    T_offset[0, 3] = 0.0
                    T_offset[1, 3] = 0.0
                    T_offset[2, 3] = 0.0
                    
                    T_cam_target = T_cam_marker @ T_offset
                    
                    # íšŒì „ í–‰ë ¬ -> Quaternion
                    rot_target = Rotation.from_matrix(T_cam_target[:3, :3])
                    quat_target = rot_target.as_quat()

                    # PoseStamped ì„¤ì •
                    p_cam = PoseStamped()
                    p_cam.header.frame_id = source_frame
                    p_cam.header.stamp = msg.header.stamp
                    
                    p_cam.pose.position.x = T_cam_target[0, 3]
                    p_cam.pose.position.y = T_cam_target[1, 3]
                    p_cam.pose.position.z = T_cam_target[2, 3]
                    
                    p_cam.pose.orientation.x = quat_target[0]
                    p_cam.pose.orientation.y = quat_target[1]
                    p_cam.pose.orientation.z = quat_target[2]
                    p_cam.pose.orientation.w = quat_target[3]

                    # TF ë³€í™˜ (Camera -> Base Link)
                    transform = self.tf_buffer.lookup_transform(
                        target_frame,
                        source_frame,
                        rclpy.time.Time(), 
                        timeout=rclpy.duration.Duration(seconds=0.1)
                    )
                    
                    p_robot_pose = tf2_geometry_msgs.do_transform_pose(p_cam.pose, transform)
                    
                    # Raw Yaw ê³„ì‚°
                    q = p_robot_pose.orientation
                    rot_base = Rotation.from_quat([q.x, q.y, q.z, q.w])
                    raw_yaw_deg = rot_base.as_euler('xyz', degrees=True)[2]
                    
                    # ì˜¤í”„ì…‹ ì ìš©
                    corrected_yaw_deg = raw_yaw_deg + self.yaw_offset
                    
                    # -180 ~ 180 ì •ê·œí™”
                    while corrected_yaw_deg > 180:
                        corrected_yaw_deg -= 360
                    while corrected_yaw_deg < -180:
                        corrected_yaw_deg += 360
                    
                    # =========================================================
                    # [ì¶”ê°€] ìŠ¤ë¬´ë”© ì ìš©
                    # =========================================================
                    raw_x = p_robot_pose.position.x
                    raw_y = p_robot_pose.position.y
                    raw_z = p_robot_pose.position.z
                    
                    smooth_x, smooth_y, smooth_z, smooth_yaw = self.smooth_pose(
                        current_id, raw_x, raw_y, raw_z, corrected_yaw_deg
                    )
                    # =========================================================
                    
                    # ê±°ë¦¬ ê³„ì‚°
                    dist = math.sqrt(smooth_x**2 + smooth_y**2 + smooth_z**2)
                    
                    # í™”ë©´ í‘œì‹œ (ìŠ¤ë¬´ë”©ëœ ê°’)
                    text = f"ID:{current_id} Dist:{dist:.2f}m Yaw:{smooth_yaw:.1f}deg"
                    cv2.putText(frame, text, (10, 30 + i*30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                    # ì½˜ì†” ë¡œê·¸ (ì²« ë²ˆì§¸ ë§ˆì»¤ë§Œ)
                    if i == 0:
                        print(f"ðŸ‘ï¸ [ArUco] ID:{current_id} | "
                              f"X:{smooth_x:.2f}, Y:{smooth_y:.2f}, Z:{smooth_z:.2f} | "
                              f"Yaw:{smooth_yaw:.1f}Â°")
                    
                    # ìŠ¤ë¬´ë”©ëœ Yaw -> Quaternion
                    corrected_rot = Rotation.from_euler('xyz', [0, 0, math.radians(smooth_yaw)])
                    corrected_quat = corrected_rot.as_quat()
                    
                    info = MarkerInfo()
                    info.id = current_id
                    
                    # ìŠ¤ë¬´ë”©ëœ ìœ„ì¹˜
                    info.pose.position.x = smooth_x
                    info.pose.position.y = smooth_y
                    info.pose.position.z = smooth_z
                    
                    # ìŠ¤ë¬´ë”©ëœ íšŒì „
                    info.pose.orientation.x = corrected_quat[0]
                    info.pose.orientation.y = corrected_quat[1]
                    info.pose.orientation.z = corrected_quat[2]
                    info.pose.orientation.w = corrected_quat[3]
                    
                    marker_array.markers.append(info)

                except (tf2_ros.LookupException, tf2_ros.ExtrapolationException) as e:
                    continue

            if len(marker_array.markers) > 0:
                self.result_pub.publish(marker_array)
                
        cv2.imshow("Aruco View", frame)
        cv2.waitKey(1)

def main():
    rclpy.init()
    node = ArucoDetector()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        cv2.destroyAllWindows()
        rclpy.shutdown()

if __name__ == '__main__':
    main()